import pandas as pd
import numpy as np
import sklearn
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix
from sklearn.ensemble import RandomForestClassifier

# ======================================================
# 1) Load TRAIN and EXTERNAL TEST CSVs
# ======================================================

train_path = "/kaggle/input/start-up-founder-retention-prediction/train.csv"
test_path  = "/kaggle/input/start-up-founder-retention-prediction/test.csv"

df = pd.read_csv(train_path)
df_ext_test = pd.read_csv(test_path)

# ======================================================
# 2) FIXED COLUMN GROUPS
# ======================================================

numeric_cols = [
    "founder_id",
    "founder_age",
    "years_with_startup",
    "monthly_revenue_generated",
    "funding_rounds_led",
    "distance_from_investor_hub",
    "num_dependents"
]

categorical_cols = [
    "founder_gender",
    "founder_role",
    "work_life_balance_rating",
    "venture_satisfaction",
    "startup_performance_rating",
    "education_background",
    "personal_status",
    "startup_stage",
    "team_size_category",
    "years_since_founding",
    "innovation_support",
    "startup_reputation"
]

boolean_cols = [
    "working_overtime",
    "remote_operations",
    "founder_visibility",
    "leadership_scope"     # correctly moved here
]

target_col = "retention_status"

# ======================================================
# 3) Normalize Booleans (handles ALL cases safely)
# ======================================================

def normalize_boolean(col):
    return (
        col.astype(str)
           .str.strip()
           .str.lower()
           .map({
               "true": 1, "false": 0,
               "yes": 1, "no": 0,
               "1": 1, "0": 0
           })
           .astype("Int64")
    )

# TRAIN
for col in boolean_cols:
    df[col] = normalize_boolean(df[col])

# EXTERNAL TEST
for col in boolean_cols:
    if col in df_ext_test.columns:
        df_ext_test[col] = normalize_boolean(df_ext_test[col])

# Convert target
df[target_col] = df[target_col].map({"Stayed": 1, "Left": 0})

# ======================================================
# 4) 80:20 SPLIT FOR VALIDATION (Evaluation ONLY)
# ======================================================

X = df.drop(columns=[target_col])
y = df[target_col]

X_train, X_val, y_train, y_val = train_test_split(
    X, y, test_size=0.20, random_state=42, stratify=y
)

# ======================================================
# 5) PREPROCESSING PIPELINES
# ======================================================

skewed_numeric_cols = ["monthly_revenue_generated", "distance_from_investor_hub"]
skew_indices = [numeric_cols.index(c) for c in skewed_numeric_cols]

def log_transform_selected(X):
    X = X.copy().astype(float)
    for idx in skew_indices:
        col = X[:, idx]
        col = np.where(col < 0, 0.0, col)
        X[:, idx] = np.log1p(col)
    return X

numeric_pipeline = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="median")),
    ("log_transform", FunctionTransformer(log_transform_selected, validate=False)),
    ("scaler", StandardScaler())
])

# Version-safe OneHotEncoder
def make_ohe():
    if sklearn.__version__ >= "1.2":
        return OneHotEncoder(handle_unknown="ignore", sparse_output=False)
    else:
        return OneHotEncoder(handle_unknown="ignore", sparse=False)

categorical_pipeline = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("ohe", make_ohe())
])

boolean_pipeline = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="most_frequent"))
])

preprocessor = ColumnTransformer(transformers=[
    ("num", numeric_pipeline, numeric_cols),
    ("cat", categorical_pipeline, categorical_cols),
    ("bool", boolean_pipeline, boolean_cols)
])

# ======================================================
# 6) MODEL PIPELINE
# ======================================================

clf = Pipeline(steps=[
    ("preprocess", preprocessor),
    ("model", RandomForestClassifier(n_estimators=300, random_state=42))
])

# Train on 80%
clf.fit(X_train, y_train)

# ======================================================
# 7) STRATIFIED K-FOLD EVALUATION ON 20% VALIDATION SET
# ======================================================

skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)
fold_f1, fold_auc = [], []
combined_cm = np.zeros((2, 2), dtype=int)

X_val_df = X_val.reset_index(drop=True)
y_val_arr = y_val.reset_index(drop=True).to_numpy()

print("\nEvaluating on validation set (20% split):")
for i, (_, val_idx) in enumerate(skf.split(X_val_df, y_val_arr), 1):
    X_fold = X_val_df.iloc[val_idx]
    y_fold = y_val_arr[val_idx]

    y_pred = clf.predict(X_fold)
    y_prob = clf.predict_proba(X_fold)[:, 1]

    f1 = f1_score(y_fold, y_pred)
    auc = roc_auc_score(y_fold, y_prob)
    cm = confusion_matrix(y_fold, y_pred)

    fold_f1.append(f1)
    fold_auc.append(auc)
    combined_cm += cm

    print(f"\nFold {i} --> F1={f1:.4f}, AUC={auc:.4f}")
    print(cm)

print("\n===== VALIDATION METRICS =====")
print("Average F1:", np.mean(fold_f1))
print("Average AUC:", np.mean(fold_auc))
print("Combined Confusion Matrix:\n", combined_cm)

# ======================================================
# 8) RETRAIN ON FULL TRAINING SET (100%)
# ======================================================

clf_full = Pipeline(steps=[
    ("preprocess", preprocessor),
    ("model", RandomForestClassifier(n_estimators=300, random_state=42))
])

clf_full.fit(X, y)
print("\nModel retrained on 100% of train.csv âœ”")

# ======================================================
# 9) APPLY FULL MODEL TO EXTERNAL TEST SET
# ======================================================

ext_pred_binary = clf_full.predict(df_ext_test)
ext_pred_label = np.where(ext_pred_binary == 1, "Stayed", "Left")

submission = pd.DataFrame({
    "founder_id": df_ext_test["founder_id"],
    "retention_status": ext_pred_label
})

submission.to_csv("submission.csv", index=False)
print("\nsubmission.csv generated successfully!")
print(submission.head())
